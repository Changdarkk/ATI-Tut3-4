{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4.2 Changing optimization parameters\n"
      ],
      "metadata": {
        "id": "ApEGsGnec6BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will use the same titanic dataset from the previous exercises. You can download the dataset from the following link:\n",
        "\n",
        "[titanic_all_numeric.csv](https://drive.google.com/file/d/11nuYS-l3EXCsGJt81y4YTt3oTnFGaB68/view?usp=drive_link)\n",
        "\n",
        "The data is pre-loaded into a pandas DataFrame called `df`. The `predictors` and `target` values are also pre-defined.\n",
        "\n",
        "You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function `get_new_model()` that creates an unoptimized model to optimize.\n",
        "\n",
        "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good."
      ],
      "metadata": {
        "id": "mEOOH6NdV42q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions"
      ],
      "metadata": {
        "id": "-AWPd5Wqft_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import `SGD` from `tensorflow.keras.optimizers`.\n",
        "* Create a list of learning rates to try optimizing with called `lr_to_test`. The learning rates in it should be `0.000001`, `0.01`, and `1.0`.\n",
        "* Using a `for` loop to iterate over `lr_to_test`:\n",
        "  * Use the `get_new_model()` function to build a new, unoptimized model.\n",
        "  * Create an optimizer called `my_optimizer` using the `SGD()` constructor with keyword argument `learning_rate=lr`.\n",
        "  * Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use `'categorical_crossentropy'` for the loss parameter, , and `metrics=['accuracy']` to see the accuracy at the end of each epoch.\n",
        "  * Fit the model using the `predictors` and the `target`."
      ],
      "metadata": {
        "id": "fNotC4abWBqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "oKx-pAyrlVGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and convert the data to NumPy array:"
      ],
      "metadata": {
        "id": "K2uQ5t2BRtpg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlu9wWcWcy44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f359d9-4389-4347-d951-39847929eb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1757448447.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load csv file into the dataframe: df\n",
        "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
        "\n",
        "# Convert the boolean values of the 'age_was_missing' column to integer\n",
        "df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
        "\n",
        "# Create predictors NumPy array: predictors\n",
        "predictors = df.drop(['survived'], axis=1).values\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(df['survived'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a neural network for a classification task"
      ],
      "metadata": {
        "id": "9jf6A0pPsATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def get_new_model():\n",
        "  # Set up the model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "wkgdNpMmsKmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimize the model with different learning rate:"
      ],
      "metadata": {
        "id": "u986qJ_NOK1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
        "\n",
        "# Convert the boolean values of the 'age_was_missing' column to integer\n",
        "df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
        "\n",
        "# Create predictors NumPy array\n",
        "predictors = df.drop(['survived'], axis=1).values\n",
        "\n",
        "# Save the number of columns in predictors\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Convert the target to categorical\n",
        "target = to_categorical(df['survived'])\n",
        "\n",
        "# Function to create a new model\n",
        "def get_new_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# List of learning rates to test\n",
        "lr_to_test = [0.000001, 0.01, 1.0]\n",
        "\n",
        "# Loop over each learning rate to test\n",
        "for lr in lr_to_test:\n",
        "    print('\\n\\nTesting model with learning rate: %f\\n' % lr)\n",
        "\n",
        "    # Build a new model for each test\n",
        "    model = get_new_model()\n",
        "\n",
        "    # Create SGD optimizer with the specified learning rate\n",
        "    my_optimizer = SGD(learning_rate=lr)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(predictors, target, epochs=10, verbose=2)\n"
      ],
      "metadata": {
        "id": "rdrPE2NrOjS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdfdbe9-a1af-4aa6-b399-ce3405a6f918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Testing model with learning rate: 0.000001\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1241465416.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 - 1s - 25ms/step - accuracy: 0.3490 - loss: 4.9521\n",
            "Epoch 2/10\n",
            "28/28 - 0s - 7ms/step - accuracy: 0.3490 - loss: 4.9305\n",
            "Epoch 3/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.3490 - loss: 4.9090\n",
            "Epoch 4/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.3490 - loss: 4.8875\n",
            "Epoch 5/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.3502 - loss: 4.8661\n",
            "Epoch 6/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.3502 - loss: 4.8448\n",
            "Epoch 7/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.3502 - loss: 4.8235\n",
            "Epoch 8/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.3502 - loss: 4.8022\n",
            "Epoch 9/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.3502 - loss: 4.7810\n",
            "Epoch 10/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.3513 - loss: 4.7598\n",
            "\n",
            "\n",
            "Testing model with learning rate: 0.010000\n",
            "\n",
            "Epoch 1/10\n",
            "28/28 - 0s - 17ms/step - accuracy: 0.5859 - loss: 2.5080\n",
            "Epoch 2/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6375 - loss: 0.9391\n",
            "Epoch 3/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6611 - loss: 0.6748\n",
            "Epoch 4/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6599 - loss: 0.6535\n",
            "Epoch 5/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.6745 - loss: 0.6611\n",
            "Epoch 6/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6947 - loss: 0.6183\n",
            "Epoch 7/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6835 - loss: 0.6104\n",
            "Epoch 8/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6813 - loss: 0.6126\n",
            "Epoch 9/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.7082 - loss: 0.5937\n",
            "Epoch 10/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6880 - loss: 0.6102\n",
            "\n",
            "\n",
            "Testing model with learning rate: 1.000000\n",
            "\n",
            "Epoch 1/10\n",
            "28/28 - 0s - 17ms/step - accuracy: 0.6072 - loss: 113.3487\n",
            "Epoch 2/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.6162 - loss: 0.6702\n",
            "Epoch 3/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6094 - loss: 0.6752\n",
            "Epoch 4/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.6162 - loss: 0.6712\n",
            "Epoch 5/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6162 - loss: 0.6689\n",
            "Epoch 6/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.6162 - loss: 0.6732\n",
            "Epoch 7/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6139 - loss: 0.6698\n",
            "Epoch 8/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6162 - loss: 0.6698\n",
            "Epoch 9/10\n",
            "28/28 - 0s - 3ms/step - accuracy: 0.6162 - loss: 0.6739\n",
            "Epoch 10/10\n",
            "28/28 - 0s - 5ms/step - accuracy: 0.6162 - loss: 0.6725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ouput should be:\n",
        "\n",
        "Testing model with learning rate: 0.000001\n",
        "\n",
        "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.4074 - loss: 5.5751   \n",
        "\n",
        "\n",
        "Testing model with learning rate: 0.010000\n",
        "\n",
        "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5747 - loss: 3.3378   \n",
        "\n",
        "\n",
        "Testing model with learning rate: 1.000000\n",
        "\n",
        "28/28 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.5404 - loss: 28697.6289\n"
      ],
      "metadata": {
        "id": "ecubSk7GZKKp"
      }
    }
  ]
}